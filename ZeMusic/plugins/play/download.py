# -*- coding: utf-8 -*-
"""
ğŸš€ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø®Ø§Ø±Ù‚ - Ù…ÙˆØ­Ø¯ Ù„Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª
=====================================================

ÙŠØ¯Ù…Ø¬ Ø¨ÙŠÙ†:
- ØªØ¯ÙˆÙŠØ± Ø§Ù„ÙƒÙˆÙƒÙŠØ² ÙˆØ§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
- ØªØ®Ø²ÙŠÙ† Ø°ÙƒÙŠ ÙÙŠ Ù‚Ù†Ø§Ø© ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… 
- Ø¨Ø­Ø« ÙØ§Ø¦Ù‚ Ø§Ù„Ø³Ø±Ø¹Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
- ØªØ­Ù…ÙŠÙ„ Ù…ØªÙˆØ§Ø²ÙŠ Ù„Ø§ Ù…Ø­Ø¯ÙˆØ¯
- ØªØ¨Ø¯ÙŠÙ„ Ø®Ø§Ø·Ù Ø¨ÙŠÙ† Ø·Ø±Ù‚ Ø§Ù„ØªØ­Ù…ÙŠÙ„
"""

import os
import re
import asyncio
import logging
import time
import sqlite3
import hashlib
import concurrent.futures
from typing import Dict, Optional, List
from itertools import cycle
import aiohttp
import aiofiles
import yt_dlp
from youtube_search import YoutubeSearch

from pyrogram import filters
from pyrogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton
from pyrogram.errors import FloodWait, RPCError, MessageIdInvalid

import config
from ZeMusic import app, LOGGER
from ZeMusic.platforms.Youtube import cookies
from ZeMusic.plugins.play.filters import command
from ZeMusic.utils.database import is_search_enabled, is_search_enabled1

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ ---
REQUEST_TIMEOUT = 10
DOWNLOAD_TIMEOUT = 120
MAX_SESSIONS = 50  # Ø¹Ø¯Ø¯ Ø¬Ù„Ø³Ø§Øª HTTP Ù…ØªÙˆØ§Ø²ÙŠØ©

# Ù‚Ù†Ø§Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø°ÙƒÙŠ
SMART_CACHE_CHANNEL = config.CACHE_CHANNEL_ID

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ø±Ø¶
channel = getattr(config, 'STORE_LINK', '')
lnk = f"https://t.me/{channel}" if channel else None

# --- ØªØ¯ÙˆÙŠØ± Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ÙˆØ§Ù„Ø®ÙˆØ§Ø¯Ù… ---
YT_API_KEYS = config.YT_API_KEYS
API_KEYS_CYCLE = cycle(YT_API_KEYS) if YT_API_KEYS else None

INVIDIOUS_SERVERS = config.INVIDIOUS_SERVERS
INVIDIOUS_CYCLE = cycle(INVIDIOUS_SERVERS) if INVIDIOUS_SERVERS else None

# ØªØ¯ÙˆÙŠØ± Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒÙˆÙƒÙŠØ²
COOKIES_FILES = config.COOKIES_FILES
COOKIES_CYCLE = cycle(COOKIES_FILES) if COOKIES_FILES else None

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª yt-dlp Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ø¯Ø§Ø¡ ---
def get_ytdlp_opts(cookies_file=None):
    opts = {
        "format": "bestaudio/best",
        "noplaylist": True,
        "quiet": True,
        "retries": 2,
        "no-cache-dir": True,
        "ignoreerrors": True,
        "socket-timeout": REQUEST_TIMEOUT,
        "force-ipv4": True,
        "throttled-rate": "1M",
        "extractor-args": "youtube:player_client=android,web",
        "concurrent-fragments": 12,
        "outtmpl": "downloads/%(id)s.%(ext)s",
        "postprocessors": [{
            "key": "FFmpegExtractAudio",
            "preferredcodec": "mp3",
            "preferredquality": "192",
        }],
        "postprocessor_args": ["-ar", "44100"],
        "noprogress": True,
        "verbose": False,
    }
    
    if cookies_file and os.path.exists(cookies_file):
        opts["cookiefile"] = cookies_file
    
    # Ø¥Ø¶Ø§ÙØ© aria2c Ø¥Ø°Ø§ Ù…ØªÙˆÙØ±
    import shutil
    if shutil.which("aria2c"):
        opts.update({
            "external_downloader": "aria2c",
            "external_downloader_args": ["-x", "16", "-s", "16", "-k", "1M"],
        })
    
    return opts

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„Ø§Øª
os.makedirs("downloads", exist_ok=True)

# --- Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ÙÙ‡Ø±Ø³Ø© Ø§Ù„Ø°ÙƒÙŠØ© ---
DB_FILE = "smart_cache.db"

def init_database():
    """ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ÙÙ‡Ø±Ø³Ø© Ø§Ù„Ø°ÙƒÙŠØ©"""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS channel_index (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            message_id INTEGER UNIQUE,
            file_id TEXT UNIQUE,
            file_unique_id TEXT,
            
            search_hash TEXT UNIQUE,
            title_normalized TEXT,
            artist_normalized TEXT,
            keywords_vector TEXT,
            
            original_title TEXT,
            original_artist TEXT,
            duration INTEGER,
            file_size INTEGER,
            
            access_count INTEGER DEFAULT 0,
            last_accessed TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            popularity_rank REAL DEFAULT 0,
            
            phonetic_hash TEXT,
            partial_matches TEXT,
            
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ù„Ù„Ø³Ø±Ø¹Ø© Ø§Ù„Ø®Ø§Ø±Ù‚Ø©
    indexes = [
        "CREATE INDEX IF NOT EXISTS idx_search_hash ON channel_index(search_hash)",
        "CREATE INDEX IF NOT EXISTS idx_title_norm ON channel_index(title_normalized)",
        "CREATE INDEX IF NOT EXISTS idx_artist_norm ON channel_index(artist_normalized)",
        "CREATE INDEX IF NOT EXISTS idx_popularity ON channel_index(popularity_rank DESC)",
        "CREATE INDEX IF NOT EXISTS idx_message_id ON channel_index(message_id)",
        "CREATE INDEX IF NOT EXISTS idx_file_id ON channel_index(file_id)"
    ]
    
    for index_sql in indexes:
        cursor.execute(index_sql)
    
    conn.commit()
    conn.close()

# ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„ÙˆØ­Ø¯Ø©
init_database()

class HyperSpeedDownloader:
    """Ù…Ø¯ÙŠØ± Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙØ§Ø¦Ù‚ Ø§Ù„Ø³Ø±Ø¹Ø©"""
    
    def __init__(self):
        self.session_pool = []
        self.executor_pool = None
        self.method_performance = {
            'cache': {'weight': 1000, 'active': True, 'avg_time': 0.001},
            'youtube_api': {'weight': 100, 'active': True, 'avg_time': 2.0},
            'invidious': {'weight': 90, 'active': True, 'avg_time': 3.0},
            'ytdlp_cookies': {'weight': 80, 'active': True, 'avg_time': 5.0},
            'ytdlp_no_cookies': {'weight': 60, 'active': True, 'avg_time': 8.0},
            'youtube_search': {'weight': 50, 'active': True, 'avg_time': 4.0}
        }
        
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
        asyncio.create_task(self.initialize())
    
    async def initialize(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø§Ù„Ø®Ø§Ø±Ù‚Ø©"""
        try:
            connector = aiohttp.TCPConnector(
                limit=1000,
                limit_per_host=200,
                ttl_dns_cache=300,
                use_dns_cache=True,
                keepalive_timeout=30,
                enable_cleanup_closed=True
            )
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø§Øª HTTP Ù…ØªØ¹Ø¯Ø¯Ø©
            for i in range(MAX_SESSIONS):
                session = aiohttp.ClientSession(
                    connector=connector,
                    timeout=aiohttp.ClientTimeout(total=REQUEST_TIMEOUT),
                    headers={'User-Agent': f'ZeMusic-{i}'}
                )
                self.session_pool.append(session)
            
            # Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Thread Ø¹Ù…Ù„Ø§Ù‚Ø©
            self.executor_pool = concurrent.futures.ThreadPoolExecutor(max_workers=100)
            
            LOGGER(__name__).info("ğŸš€ ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø®Ø§Ø±Ù‚")
            
        except Exception as e:
            LOGGER(__name__).error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {e}")
    
    def normalize_text(self, text: str) -> str:
        """ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ Ù„Ù„Ø¨Ø­Ø«"""
        if not text:
            return ""
        
        # ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ø£Ø­Ø±Ù Ø§Ù„ØµØºÙŠØ±Ø© ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„
        text = text.lower()
        text = re.sub(r'[Ù‹ÙŒÙÙÙÙÙ‘Ù’]', '', text)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„
        text = re.sub(r'[^\w\s]', '', text)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ²
        text = re.sub(r'\s+', ' ', text).strip()  # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
        
        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        replacements = {
            'Ø©': 'Ù‡', 'ÙŠ': 'Ù‰', 'Ø£': 'Ø§', 'Ø¥': 'Ø§',
            'Ø¢': 'Ø§', 'Ø¤': 'Ùˆ', 'Ø¦': 'ÙŠ'
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        return text
    
    def create_search_hash(self, title: str, artist: str = "") -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø§Ø´ Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹"""
        normalized_title = self.normalize_text(title)
        normalized_artist = self.normalize_text(artist)
        combined = f"{normalized_title}_{normalized_artist}"
        return hashlib.md5(combined.encode()).hexdigest()[:16]
    
    async def lightning_search_cache(self, query: str) -> Optional[Dict]:
        """Ø¨Ø­Ø« Ø®Ø§Ø·Ù ÙÙŠ Ø§Ù„ÙƒØ§Ø´ (Ø£Ù‚Ù„ Ù…Ù† 0.001 Ø«Ø§Ù†ÙŠØ©)"""
        try:
            normalized_query = self.normalize_text(query)
            search_hash = self.create_search_hash(normalized_query)
            
            conn = sqlite3.connect(DB_FILE)
            cursor = conn.cursor()
            
            # Ø¨Ø­Ø« Ù…Ø¨Ø§Ø´Ø± Ø¨Ø§Ù„Ù‡Ø§Ø´
            cursor.execute(
                "SELECT message_id, file_id, original_title, original_artist, duration FROM channel_index WHERE search_hash = ? LIMIT 1",
                (search_hash,)
            )
            result = cursor.fetchone()
            
            if result:
                # ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
                cursor.execute(
                    "UPDATE channel_index SET access_count = access_count + 1, last_accessed = CURRENT_TIMESTAMP WHERE search_hash = ?",
                    (search_hash,)
                )
                conn.commit()
                conn.close()
                
                return {
                    'message_id': result[0],
                    'file_id': result[1],
                    'title': result[2],
                    'artist': result[3],
                    'duration': result[4],
                    'source': 'cache',
                    'cached': True
                }
            
            # Ø¨Ø­Ø« ØªÙ‚Ø±ÙŠØ¨ÙŠ
            cursor.execute(
                "SELECT message_id, file_id, original_title, original_artist, duration FROM channel_index WHERE title_normalized LIKE ? OR keywords_vector LIKE ? LIMIT 1",
                (f'%{normalized_query}%', f'%{normalized_query}%')
            )
            result = cursor.fetchone()
            
            conn.close()
            
            if result:
                return {
                    'message_id': result[0],
                    'file_id': result[1],
                    'title': result[2],
                    'artist': result[3],
                    'duration': result[4],
                    'source': 'cache_fuzzy',
                    'cached': True
                }
            
        except Exception as e:
            LOGGER(__name__).error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹: {e}")
        
        return None
    
    async def get_session(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ù‚Ù„ Ø¬Ù„Ø³Ø© Ù…Ø´ØºÙˆÙ„Ø©"""
        if not self.session_pool:
            await self.initialize()
        return self.session_pool[0]  # ØªØ¨Ø³ÙŠØ· Ù„Ù„Ø¢Ù†
    
    async def youtube_api_search(self, query: str) -> Optional[Dict]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ø¨Ø± YouTube Data API"""
        if not API_KEYS_CYCLE:
            return None
        
        session = await self.get_session()
        
        for _ in range(len(YT_API_KEYS)):
            try:
                key = next(API_KEYS_CYCLE)
                params = {
                    "part": "snippet",
                    "q": query,
                    "type": "video",
                    "maxResults": 1,
                    "key": key
                }
                
                async with session.get("https://www.googleapis.com/youtube/v3/search", params=params) as resp:
                    if resp.status != 200:
                        continue
                    
                    data = await resp.json()
                    items = data.get("items", [])
                    if not items:
                        continue
                    
                    item = items[0]
                    video_id = item["id"]["videoId"]
                    snippet = item["snippet"]
                    
                    return {
                        "video_id": video_id,
                        "title": snippet.get("title", "")[:60],
                        "artist": snippet.get("channelTitle", "Unknown"),
                        "thumb": snippet.get("thumbnails", {}).get("high", {}).get("url"),
                        "source": "youtube_api"
                    }
                    
            except Exception as e:
                LOGGER(__name__).warning(f"ÙØ´Ù„ YouTube API: {e}")
                continue
        
        return None
    
    async def invidious_search(self, query: str) -> Optional[Dict]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ø¨Ø± Invidious"""
        if not INVIDIOUS_CYCLE:
            return None
        
        session = await self.get_session()
        
        for _ in range(len(INVIDIOUS_SERVERS)):
            try:
                server = next(INVIDIOUS_CYCLE)
                url = f"{server}/api/v1/search"
                params = {"q": query, "type": "video"}
                
                async with session.get(url, params=params) as resp:
                    if resp.status != 200:
                        continue
                    
                    data = await resp.json()
                    video = next((item for item in data if item.get("type") == "video"), None)
                    if not video:
                        continue
                    
                    return {
                        "video_id": video.get("videoId"),
                        "title": video.get("title", "")[:60],
                        "artist": video.get("author", "Unknown"),
                        "duration": int(video.get("lengthSeconds", 0)),
                        "thumb": next(
                            (t.get("url") for t in reversed(video.get("videoThumbnails", []))),
                            None
                        ),
                        "source": "invidious"
                    }
                    
            except Exception as e:
                LOGGER(__name__).warning(f"ÙØ´Ù„ Invidious: {e}")
                continue
        
        return None
    
    async def youtube_search_simple(self, query: str) -> Optional[Dict]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ø¨Ø± youtube_search"""
        try:
            results = YoutubeSearch(query, max_results=1).to_dict()
            if not results:
                return None
            
            result = results[0]
            return {
                "video_id": result["id"],
                "title": result["title"][:60],
                "artist": result.get("channel", "Unknown"),
                "duration": result.get("duration", ""),
                "thumb": result["thumbnails"][0] if result.get("thumbnails") else None,
                "link": f"https://youtube.com{result['url_suffix']}",
                "source": "youtube_search"
            }
            
        except Exception as e:
            LOGGER(__name__).warning(f"ÙØ´Ù„ YouTube Search: {e}")
            return None
    
    async def download_with_ytdlp(self, video_info: Dict) -> Optional[Dict]:
        """ØªØ­Ù…ÙŠÙ„ Ø¹Ø¨Ø± yt-dlp Ù…Ø¹ ØªØ¯ÙˆÙŠØ± Ø§Ù„ÙƒÙˆÙƒÙŠØ²"""
        video_id = video_info.get("video_id")
        if not video_id:
            return None
        
        url = f"https://youtu.be/{video_id}"
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹ Ø§Ù„ÙƒÙˆÙƒÙŠØ² Ø£ÙˆÙ„Ø§Ù‹
        if COOKIES_CYCLE:
            for _ in range(len(COOKIES_FILES)):
                try:
                    cookies_file = next(COOKIES_CYCLE)
                    opts = get_ytdlp_opts(cookies_file)
                    
                    loop = asyncio.get_running_loop()
                    info = await loop.run_in_executor(
                        self.executor_pool,
                        lambda: yt_dlp.YoutubeDL(opts).extract_info(url, download=True)
                    )
                    
                    if info:
                        audio_path = f"downloads/{video_id}.mp3"
                        if os.path.exists(audio_path):
                            return {
                                "audio_path": audio_path,
                                "title": info.get("title", video_info.get("title", ""))[:60],
                                "artist": info.get("uploader", video_info.get("artist", "Unknown")),
                                "duration": int(info.get("duration", 0)),
                                "file_size": os.path.getsize(audio_path),
                                "source": f"ytdlp_cookies_{cookies_file}"
                            }
                
                except Exception as e:
                    LOGGER(__name__).warning(f"ÙØ´Ù„ yt-dlp Ù…Ø¹ ÙƒÙˆÙƒÙŠØ² {cookies_file}: {e}")
                    continue
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯ÙˆÙ† ÙƒÙˆÙƒÙŠØ²
        try:
            opts = get_ytdlp_opts()
            loop = asyncio.get_running_loop()
            info = await loop.run_in_executor(
                self.executor_pool,
                lambda: yt_dlp.YoutubeDL(opts).extract_info(url, download=True)
            )
            
            if info:
                audio_path = f"downloads/{video_id}.mp3"
                if os.path.exists(audio_path):
                    return {
                        "audio_path": audio_path,
                        "title": info.get("title", video_info.get("title", ""))[:60],
                        "artist": info.get("uploader", video_info.get("artist", "Unknown")),
                        "duration": int(info.get("duration", 0)),
                        "file_size": os.path.getsize(audio_path),
                        "source": "ytdlp_no_cookies"
                    }
        
        except Exception as e:
            LOGGER(__name__).error(f"ÙØ´Ù„ yt-dlp Ø¨Ø¯ÙˆÙ† ÙƒÙˆÙƒÙŠØ²: {e}")
        
        return None
    
    async def cache_to_channel(self, audio_info: Dict, search_query: str) -> Optional[str]:
        """Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ù‚Ù†Ø§Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† ÙˆÙ‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        if not SMART_CACHE_CHANNEL:
            return None
        
        try:
            audio_path = audio_info["audio_path"]
            title = audio_info["title"]
            artist = audio_info["artist"]
            duration = audio_info["duration"]
            file_size = audio_info["file_size"]
            
            # Ø¥Ù†Ø´Ø§Ø¡ caption Ù„Ù„Ù…Ù„Ù
            caption = f"""ğŸµ {title}
ğŸ¤ {artist}
â±ï¸ {duration}s | ğŸ“Š {file_size/1024/1024:.1f}MB
ğŸ”— {audio_info["source"]}
ğŸ” {search_query}"""
            
            # Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ù„Ù„Ù‚Ù†Ø§Ø©
            message = await app.send_audio(
                chat_id=SMART_CACHE_CHANNEL,
                audio=audio_path,
                title=title,
                performer=artist,
                duration=duration,
                caption=caption
            )
            
            # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            search_hash = self.create_search_hash(title, artist)
            normalized_title = self.normalize_text(title)
            normalized_artist = self.normalize_text(artist)
            keywords = f"{normalized_title} {normalized_artist} {self.normalize_text(search_query)}"
            
            conn = sqlite3.connect(DB_FILE)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT OR REPLACE INTO channel_index 
                (message_id, file_id, file_unique_id, search_hash, title_normalized, artist_normalized, 
                 keywords_vector, original_title, original_artist, duration, file_size)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                message.id, message.audio.file_id, message.audio.file_unique_id,
                search_hash, normalized_title, normalized_artist, keywords,
                title, artist, duration, file_size
            ))
            
            conn.commit()
            conn.close()
            
            LOGGER(__name__).info(f"âœ… ØªÙ… Ø­ÙØ¸ {title} ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø°ÙƒÙŠ")
            return message.audio.file_id
            
        except Exception as e:
            LOGGER(__name__).error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ØªØ®Ø²ÙŠÙ†: {e}")
        
        return None
    
    async def hyper_download(self, query: str) -> Optional[Dict]:
        """Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø®Ø§Ø±Ù‚ Ù„Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø±Ù‚"""
        start_time = time.time()
        
        try:
            # Ø®Ø·ÙˆØ© 1: Ø§Ù„Ø¨Ø­Ø« Ø§Ù„ÙÙˆØ±ÙŠ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
            cached_result = await self.lightning_search_cache(query)
            if cached_result:
                LOGGER(__name__).info(f"âš¡ ÙƒØ§Ø´ ÙÙˆØ±ÙŠ: {query} ({time.time() - start_time:.3f}s)")
                return cached_result
            
            # Ø®Ø·ÙˆØ© 2: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ
            search_tasks = []
            
            if API_KEYS_CYCLE:
                search_tasks.append(('youtube_api', self.youtube_api_search(query)))
            if INVIDIOUS_CYCLE:
                search_tasks.append(('invidious', self.invidious_search(query)))
            search_tasks.append(('youtube_search', self.youtube_search_simple(query)))
            
            # ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ
            search_results = await asyncio.gather(*[task for _, task in search_tasks], return_exceptions=True)
            
            # Ø£Ø®Ø° Ø£ÙˆÙ„ Ù†ØªÙŠØ¬Ø© Ù†Ø§Ø¬Ø­Ø©
            video_info = None
            for i, result in enumerate(search_results):
                if isinstance(result, dict) and result.get("video_id"):
                    video_info = result
                    break
            
            if not video_info:
                return None
            
            # Ø®Ø·ÙˆØ© 3: ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª
            audio_info = await self.download_with_ytdlp(video_info)
            if not audio_info:
                return None
            
            # Ø®Ø·ÙˆØ© 4: Ø­ÙØ¸ ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø°ÙƒÙŠ (ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©)
            if SMART_CACHE_CHANNEL:
                asyncio.create_task(self.cache_to_channel(audio_info, query))
            
            LOGGER(__name__).info(f"âœ… ØªØ­Ù…ÙŠÙ„ Ø¬Ø¯ÙŠØ¯: {query} ({time.time() - start_time:.3f}s)")
            
            return {
                'audio_path': audio_info['audio_path'],
                'title': audio_info['title'],
                'artist': audio_info['artist'],
                'duration': audio_info['duration'],
                'source': audio_info['source'],
                'cached': False
            }
            
        except Exception as e:
            LOGGER(__name__).error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø®Ø§Ø±Ù‚: {e}")
            return None

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ
downloader = HyperSpeedDownloader()

async def remove_temp_files(*paths):
    """Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©"""
    for path in paths:
        if path and os.path.exists(path):
            try:
                os.remove(path)
            except Exception as e:
                LOGGER(__name__).warning(f"ÙØ´Ù„ Ø­Ø°Ù {path}: {e}")

async def download_thumbnail(url: str, title: str) -> Optional[str]:
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ØµØºØ±Ø©"""
    if not url:
        return None
    
    try:
        title_clean = re.sub(r'[\\/*?:"<>|]', "", title)
        thumb_path = f"downloads/thumb_{title_clean[:20]}.jpg"
        
        session = await downloader.get_session()
        async with session.get(url) as resp:
            if resp.status == 200:
                async with aiofiles.open(thumb_path, mode='wb') as f:
                    await f.write(await resp.read())
                return thumb_path
    except Exception as e:
        LOGGER(__name__).warning(f"ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {e}")
    
    return None

# --- Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù…ÙˆØ­Ø¯ Ù„Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª ---
@app.on_message(
    command(["song", "/song", "Ø¨Ø­Ø«", config.BOT_NAME + " Ø§Ø¨Ø­Ø«", "ÙŠÙˆØª"]) & 
    (filters.private | filters.group | filters.channel)
)
async def smart_download_handler(client, message: Message):
    """Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù…ÙˆØ­Ø¯ Ù„Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ"""
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø©
    try:
        if message.chat.type == "private":
            if not await is_search_enabled1():
                return await message.reply_text("âŸ¡ Ø¹Ø°Ø±Ø§Ù‹ Ø¹Ø²ÙŠØ²ÙŠ Ø§Ù„ÙŠÙˆØªÙŠÙˆØ¨ Ù…Ø¹Ø·Ù„ Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø·ÙˆØ±")
        else:
            if not await is_search_enabled():
                return await message.reply_text("âŸ¡ Ø¹Ø°Ø±Ø§Ù‹ Ø¹Ø²ÙŠØ²ÙŠ Ø§Ù„ÙŠÙˆØªÙŠÙˆØ¨ Ù…Ø¹Ø·Ù„ Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø·ÙˆØ±")
    except:
        pass
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…
    query = " ".join(message.command[1:])
    if not query:
        return await message.reply_text("ğŸ“ **Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:** `Ø¨Ø­Ø« Ø§Ø³Ù… Ø§Ù„Ø£ØºÙ†ÙŠØ©`")
    
    # Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    status_msg = await message.reply_text("âš¡ **Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ...**")
    
    try:
        # Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø®Ø§Ø±Ù‚
        result = await downloader.hyper_download(query)
        
        if not result:
            await status_msg.edit_text("âŒ **ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ØŒ Ø¬Ø±Ø¨ Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Ù‹ Ø¢Ø®Ø±**")
            return
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø±Ø³Ø§Ù„Ø©
        source_emoji = {
            'cache': 'âš¡ Ù…Ù† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø³Ø±ÙŠØ¹',
            'youtube_api': 'ğŸ” YouTube API',
            'invidious': 'ğŸŒ Invidious',
            'ytdlp_cookies': 'ğŸª ØªØ­Ù…ÙŠÙ„ Ù…Ø¹ ÙƒÙˆÙƒÙŠØ²',
            'ytdlp_no_cookies': 'ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù…Ø¨Ø§Ø´Ø±',
            'youtube_search': 'ğŸ” Ø¨Ø­Ø« ÙŠÙˆØªÙŠÙˆØ¨'
        }
        
        source_text = source_emoji.get(result['source'], result['source'])
        await status_msg.edit_text(f"ğŸµ **ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰:** {result['title']}\nğŸ“¡ **Ø§Ù„Ù…ØµØ¯Ø±:** {source_text}\nâ¬†ï¸ **Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø±ÙØ¹...**")
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ù„Ù Ù„Ù„Ø¥Ø±Ø³Ø§Ù„
        if result.get('cached') and result.get('file_id'):
            # Ø¥Ø±Ø³Ø§Ù„ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
            await message.reply_audio(
                audio=result['file_id'],
                caption=f"ğŸµ **{result['title']}**\nğŸ¤ **{result['artist']}**\nğŸ“¡ **{source_text}**",
                reply_markup=InlineKeyboardMarkup([[
                    InlineKeyboardButton("ğŸ“¢ Ù‚Ù†Ø§Ø© Ø§Ù„Ø¨ÙˆØª", url=lnk)
                ]]) if lnk else None
            )
        else:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ØµØºØ±Ø©
            thumb_path = None
            if 'thumb' in result and result['thumb']:
                thumb_path = await download_thumbnail(result['thumb'], result['title'])
            
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯
            await message.reply_audio(
                audio=result['audio_path'],
                title=result['title'],
                performer=result['artist'],
                duration=result.get('duration', 0),
                thumb=thumb_path,
                caption=f"ğŸµ **{result['title']}**\nğŸ¤ **{result['artist']}**\nğŸ“¡ **{source_text}**",
                reply_markup=InlineKeyboardMarkup([[
                    InlineKeyboardButton("ğŸ“¢ Ù‚Ù†Ø§Ø© Ø§Ù„Ø¨ÙˆØª", url=lnk)
                ]]) if lnk else None
            )
            
            # Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            await remove_temp_files(result.get('audio_path'), thumb_path)
        
        # Ø­Ø°Ù Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        try:
            await status_msg.delete()
        except:
            pass
        
    except Exception as e:
        LOGGER(__name__).error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬: {e}")
        try:
            await status_msg.edit_text(f"âŒ **Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:** {str(e)}")
        except:
            pass

# --- Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø© Ù„Ù„Ù…Ø·ÙˆØ± ---
@app.on_message(command(["cache_stats"]) & filters.user(config.OWNER_ID))
async def cache_stats_handler(client, message: Message):
    """Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø°ÙƒÙŠ"""
    try:
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM channel_index")
        total_cached = cursor.fetchone()[0]
        
        cursor.execute("SELECT SUM(access_count) FROM channel_index")
        total_hits = cursor.fetchone()[0] or 0
        
        cursor.execute("SELECT original_title, access_count FROM channel_index ORDER BY access_count DESC LIMIT 5")
        top_songs = cursor.fetchall()
        
        conn.close()
        
        stats_text = f"""ğŸ“Š **Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø°ÙƒÙŠ**

ğŸ’¾ **Ø§Ù„Ù…Ø­ÙÙˆØ¸:** {total_cached} Ù…Ù„Ù
âš¡ **Ù…Ø±Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:** {total_hits}
ğŸ“ˆ **Ù…Ø¹Ø¯Ù„ Ø§Ù„ÙƒÙØ§Ø¡Ø©:** {(total_hits/max(1,total_cached)):.1f}

ğŸµ **Ø§Ù„Ø£ÙƒØ«Ø± Ø·Ù„Ø¨Ø§Ù‹:**
"""
        
        for i, (title, count) in enumerate(top_songs, 1):
            stats_text += f"{i}. {title[:30]}... ({count})\n"
        
        await message.reply_text(stats_text)
        
    except Exception as e:
        await message.reply_text(f"âŒ Ø®Ø·Ø£: {e}")

LOGGER(__name__).info("ğŸš€ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø®Ø§Ø±Ù‚")
