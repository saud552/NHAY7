"""
ğŸµ YouTube Platform Handler - Enhanced Edition
ØªØ·ÙˆÙŠØ±: ZeMusic Bot Team

Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©:
- Ù†Ø¸Ø§Ù… ØªØ­Ù…ÙŠÙ„ Ø°ÙƒÙŠ Ù…Ø¹ ÙƒØ§Ø´ Ù…ØªÙ‚Ø¯Ù…
- ØªØ¯ÙˆÙŠØ± ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„ÙƒÙˆÙƒÙŠØ² ÙˆÙ…ÙØ§ØªÙŠØ­ API
- Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ø´Ø§Ù…Ù„Ø© ÙˆÙ…ØªÙ‚Ø¯Ù…Ø©
- Ø¯Ø¹Ù… Ø®ÙˆØ§Ø¯Ù… Invidious Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©
- Ù†Ø¸Ø§Ù… Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆÙ…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡
- ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±
"""

import asyncio
import glob
import os
import random
import re
import logging
import time
import hashlib
import json
from typing import Union, Dict, List, Optional, Tuple
from itertools import cycle
from datetime import datetime, timedelta
from dataclasses import dataclass
from pathlib import Path

from ZeMusic.pyrogram_compatibility.enums import MessageEntityType
from ZeMusic.pyrogram_compatibility.types import Message
from youtubesearchpython.__future__ import VideosSearch
from yt_dlp import YoutubeDL

import config
from ZeMusic import app
from ZeMusic.utils.database import is_on_off
from ZeMusic.utils.formatters import time_to_seconds, seconds_to_min
from ZeMusic.utils.decorators import asyncify

# =============================================================================
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
# =============================================================================

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯ÙˆÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù†Ø©
YT_API_KEYS = getattr(config, "YT_API_KEYS", [])[:]
API_KEYS_CYCLE = cycle(YT_API_KEYS) if YT_API_KEYS else None
INVIDIOUS_SERVERS = getattr(config, "INVIDIOUS_SERVERS", [])
INVIDIOUS_CYCLE = cycle(INVIDIOUS_SERVERS) if INVIDIOUS_SERVERS else None

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„ØªØ²Ø§Ù…Ù† ÙˆØ§Ù„Ø£Ø¯Ø§Ø¡
DOWNLOAD_SEMAPHORE = asyncio.Semaphore(15)  # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­
SEARCH_SEMAPHORE = asyncio.Semaphore(20)    # Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹
CONCURRENT_DOWNLOADS = 10

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙƒØ§Ø´
CACHE_DIR = Path("cache/youtube")
CACHE_DIR.mkdir(parents=True, exist_ok=True)
CACHE_DURATION = timedelta(hours=6)  # Ù…Ø¯Ø© ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„ÙƒØ§Ø´

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù…ÙŠÙ„
DOWNLOADS_DIR = Path("downloads")
DOWNLOADS_DIR.mkdir(exist_ok=True)

# ØªÙƒÙˆÙŠÙ† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
performance_stats = {
    'total_downloads': 0,
    'successful_downloads': 0,
    'failed_downloads': 0,
    'cache_hits': 0,
    'api_calls': 0,
    'last_reset': time.time()
}

@dataclass
class VideoInfo:
    """ÙƒÙ„Ø§Ø³ Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"""
    title: str
    duration: str
    duration_sec: int
    thumbnail: str
    video_id: str
    link: str
    uploader: str = ""
    view_count: int = 0
    upload_date: str = ""
    quality_formats: List[Dict] = None

@dataclass
class DownloadResult:
    """Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„"""
    success: bool
    file_path: Optional[str]
    error_message: Optional[str]
    file_size: int = 0
    download_time: float = 0.0

# =============================================================================
# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù…Ø­Ø³Ù†Ø©
# =============================================================================

def cookies():
    """Ø¥Ø±Ø¬Ø§Ø¹ Ù…Ø³Ø§Ø± Ù…Ù„Ù ÙƒÙˆÙƒÙŠØ² Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ù…Ø¹ ÙÙ„ØªØ±Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµØ§Ù„Ø­Ø©"""
    try:
        folder_path = Path("cookies")
        folder_path.mkdir(exist_ok=True)
        
        txt_files = list(folder_path.glob("*.txt"))
        
        # ÙÙ„ØªØ±Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµØ§Ù„Ø­Ø© ÙÙ‚Ø·
        valid_files = []
        for file_path in txt_files:
            if file_path.stat().st_size > 0:  # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù„Ù Ù„ÙŠØ³ ÙØ§Ø±ØºØ§Ù‹
                valid_files.append(str(file_path))
        
        if not valid_files:
            logger.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª ÙƒÙˆÙƒÙŠØ² ØµØ§Ù„Ø­Ø©")
            return None
            
        selected_file = random.choice(valid_files)
        logger.debug(f"ğŸª ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ù…Ù„Ù ÙƒÙˆÙƒÙŠØ²: {selected_file}")
        return selected_file
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¯Ø§Ù„Ø© Ø§Ù„ÙƒÙˆÙƒÙŠØ²: {str(e)}")
        return None

def get_cache_key(query: str, query_type: str = "search") -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙØªØ§Ø­ ÙƒØ§Ø´ ÙØ±ÙŠØ¯"""
    content = f"{query_type}:{query}:{time.strftime('%Y-%m-%d-%H')}"
    return hashlib.md5(content.encode()).hexdigest()

async def get_from_cache(cache_key: str) -> Optional[Dict]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„ÙƒØ§Ø´"""
    try:
        cache_file = CACHE_DIR / f"{cache_key}.json"
        
        if not cache_file.exists():
            return None
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„ÙƒØ§Ø´
        file_time = datetime.fromtimestamp(cache_file.stat().st_mtime)
        if datetime.now() - file_time > CACHE_DURATION:
            cache_file.unlink()  # Ø­Ø°Ù Ø§Ù„ÙƒØ§Ø´ Ø§Ù„Ù…Ù†ØªÙ‡ÙŠ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©
            return None
        
        with open(cache_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            performance_stats['cache_hits'] += 1
            logger.debug(f"ğŸ“¦ ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒØ§Ø´: {cache_key}")
            return data
            
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ÙƒØ§Ø´: {str(e)}")
        return None

async def save_to_cache(cache_key: str, data: Dict):
    """Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„ÙƒØ§Ø´"""
    try:
        cache_file = CACHE_DIR / f"{cache_key}.json"
        
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
        logger.debug(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„ÙƒØ§Ø´: {cache_key}")
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ÙƒØ§Ø´: {str(e)}")

async def shell_cmd(cmd: str, timeout: int = 300) -> str:
    """ØªÙ†ÙÙŠØ° Ø£Ù…Ø± shell Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„Ø£Ø®Ø·Ø§Ø¡"""
    try:
        proc = await asyncio.wait_for(
            asyncio.create_subprocess_shell(
                cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
            ),
            timeout=timeout
        )
        
        out, errorz = await proc.communicate()
        
        if errorz:
            error_msg = errorz.decode("utf-8")
            # ØªØ¬Ø§Ù‡Ù„ Ø¨Ø¹Ø¶ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
            ignored_warnings = [
                "unavailable videos are hidden",
                "requested format not available",
                "falling back to"
            ]
            
            if any(warning in error_msg.lower() for warning in ignored_warnings):
                return out.decode("utf-8")
            
            logger.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± shell: {error_msg}")
            return error_msg
            
        return out.decode("utf-8")
        
    except asyncio.TimeoutError:
        logger.error(f"â° Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ù…Ø±: {cmd}")
        return "Ø®Ø·Ø£: Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„ØªÙ†ÙÙŠØ°"
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ shell_cmd: {str(e)}")
        return str(e)

def convert_duration(duration: str) -> int:
    """ØªØ­ÙˆÙŠÙ„ Ù…Ø¯Ø© YouTube (ISO 8601) Ø¥Ù„Ù‰ Ø«ÙˆØ§Ù†ÙŠ Ù…Ø¹ Ø¯Ø¹Ù… ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©"""
    if not duration:
        return 0
        
    try:
        # ØªÙ†Ø³ÙŠÙ‚ ISO 8601 (PT4M13S)
        iso_match = re.match(r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?', duration)
        if iso_match:
            hours = int(iso_match.group(1)) if iso_match.group(1) else 0
            minutes = int(iso_match.group(2)) if iso_match.group(2) else 0
            seconds = int(iso_match.group(3)) if iso_match.group(3) else 0
            return hours * 3600 + minutes * 60 + seconds
        
        # ØªÙ†Ø³ÙŠÙ‚ Ø¹Ø§Ø¯ÙŠ (4:13)
        time_parts = duration.split(':')
        if len(time_parts) == 2:  # MM:SS
            return int(time_parts[0]) * 60 + int(time_parts[1])
        elif len(time_parts) == 3:  # HH:MM:SS
            return int(time_parts[0]) * 3600 + int(time_parts[1]) * 60 + int(time_parts[2])
            
    except (ValueError, AttributeError) as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¯Ø© '{duration}': {str(e)}")
    
    return 0

def get_next_api_key() -> Optional[str]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ API Ø§Ù„ØªØ§Ù„ÙŠ"""
    if API_KEYS_CYCLE:
        return next(API_KEYS_CYCLE)
    return None

def get_next_invidious_server() -> Optional[str]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø®Ø§Ø¯Ù… Invidious Ø§Ù„ØªØ§Ù„ÙŠ"""
    if INVIDIOUS_CYCLE:
        return next(INVIDIOUS_CYCLE)
    return None

def reset_performance_stats():
    """Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
    global performance_stats
    performance_stats = {
        'total_downloads': 0,
        'successful_downloads': 0,
        'failed_downloads': 0,
        'cache_hits': 0,
        'api_calls': 0,
        'last_reset': time.time()
    }

def get_performance_report() -> Dict:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡"""
    uptime = time.time() - performance_stats['last_reset']
    success_rate = 0
    if performance_stats['total_downloads'] > 0:
        success_rate = (performance_stats['successful_downloads'] / performance_stats['total_downloads']) * 100
    
    return {
        'uptime_hours': uptime / 3600,
        'total_downloads': performance_stats['total_downloads'],
        'success_rate': f"{success_rate:.1f}%",
        'cache_efficiency': f"{performance_stats['cache_hits']} hits",
        'api_calls': performance_stats['api_calls']
    }

# =============================================================================
# ÙƒÙ„Ø§Ø³ YouTube API Ø§Ù„Ù…Ø·ÙˆØ±
# =============================================================================

class YouTubeAPI:
    """ÙØ¦Ø© YouTube API Ù…Ø­Ø³Ù†Ø© Ù…Ø¹ Ù…ÙŠØ²Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©"""
    
    def __init__(self):
        self.base = "https://www.youtube.com/watch?v="
        self.regex = r"(?:youtube\.com|youtu\.be)"
        self.status = "https://www.youtube.com/oembed?url="
        self.listbase = "https://youtube.com/playlist?list="
        self.reg = re.compile(r"\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])")
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª yt-dlp Ù…Ø­Ø³Ù†Ø©
        self.base_ytdl_opts = {
            "quiet": True,
            "no_warnings": True,
            "geo_bypass": True,
            "nocheckcertificate": True,
            "extract_flat": False,
            "writethumbnail": False,
            "writeinfojson": False,
        }

    async def exists(self, link: str, videoid: Union[bool, str] = None) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø±Ø§Ø¨Ø· YouTube Ù…Ø¹ ÙØ­Øµ Ù…Ø­Ø³Ù†"""
        try:
            if videoid:
                link = self.base + link
            
            # ÙØ­Øµ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø£ÙˆÙ„Ø§Ù‹
            if not re.search(self.regex, link):
                return False
            
            # ÙØ­Øµ ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ø±Ø§Ø¨Ø·
            try:
                import aiohttp
                async with aiohttp.ClientSession() as session:
                    async with session.head(self.status + link, timeout=5) as response:
                        return response.status == 200
            except ImportError:
                # aiohttp ØºÙŠØ± Ù…ØªÙˆÙØ±ØŒ Ù†ÙØªØ±Ø¶ Ø£Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ØµØ§Ù„Ø­
                logger.debug("aiohttp ØºÙŠØ± Ù…ØªÙˆÙØ±ØŒ ØªØ®Ø·ÙŠ ÙØ­Øµ ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ø±Ø§Ø¨Ø·")
                return True
            except:
                # Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ÙØ­ØµØŒ Ù†ÙØªØ±Ø¶ Ø£Ù†Ù‡ ØµØ§Ù„Ø­
                return True
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„Ø±Ø§Ø¨Ø·: {str(e)}")
            return False

    @asyncify
    def url(self, message_1: Message) -> Union[str, None]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ø§Ø¨Ø· Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø­Ø³Ù†Ø©"""
        try:
            messages = [message_1]
            if message_1.reply_to_message:
                messages.append(message_1.reply_to_message)
            
            for message in messages:
                # ÙØ­Øµ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ù†Øµ
                if message.entities:
                    for entity in message.entities:
                        if entity.type in [MessageEntityType.URL, MessageEntityType.TEXT_LINK]:
                            if entity.type == MessageEntityType.URL:
                                text = message.text or message.caption
                                url = text[entity.offset : entity.offset + entity.length]
                            else:
                                url = entity.url
                            
                            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù†Ù‡ Ø±Ø§Ø¨Ø· YouTube
                            if re.search(self.regex, url):
                                return url
                
                # ÙØ­Øµ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„ØªØ³Ù…ÙŠØ© Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ©
                if message.caption_entities:
                    for entity in message.caption_entities:
                        if entity.type == MessageEntityType.TEXT_LINK:
                            url = entity.url
                            if re.search(self.regex, url):
                                return url
                
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±Ø§Ø¨Ø· ÙÙŠ Ø§Ù„Ù†Øµ Ù…Ø¨Ø§Ø´Ø±Ø©
                text_content = message.text or message.caption or ""
                url_pattern = r'https?://(?:www\.)?(youtube\.com/watch\?v=|youtu\.be/)[\w-]+'
                match = re.search(url_pattern, text_content)
                if match:
                    return match.group(0)
                    
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±Ø§Ø¨Ø·: {str(e)}")
        
        return None

    async def details(self, link: str, videoid: Union[bool, str] = None) -> Tuple[str, str, int, str, str]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ø¹ ÙƒØ§Ø´ Ø°ÙƒÙŠ"""
        try:
            if videoid:
                link = self.base + link
            if "&" in link:
                link = link.split("&")[0]
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´ Ø£ÙˆÙ„Ø§Ù‹
            cache_key = get_cache_key(link, "details")
            cached_data = await get_from_cache(cache_key)
            
            if cached_data:
                return (
                    cached_data['title'],
                    cached_data['duration_min'],
                    cached_data['duration_sec'],
                    cached_data['thumbnail'],
                    cached_data['vidid']
                )
            
            # Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
            async with SEARCH_SEMAPHORE:
                results = VideosSearch(link, limit=1)
                search_result = await results.next()
                
                for result in search_result.get("result", []):
                    title = result.get("title", "Unknown")
                    duration_min = result.get("duration", "0:00")
                    thumbnail = result.get("thumbnails", [{}])[0].get("url", "").split("?")[0]
                    vidid = result.get("id", "")
                    
                    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¯Ø©
                    duration_sec = 0 if str(duration_min) == "None" else convert_duration(duration_min)
                    if duration_sec == 0:
                        duration_sec = time_to_seconds(duration_min) if duration_min else 0
                    
                    # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
                    cache_data = {
                        'title': title,
                        'duration_min': duration_min,
                        'duration_sec': duration_sec,
                        'thumbnail': thumbnail,
                        'vidid': vidid
                    }
                    await save_to_cache(cache_key, cache_data)
                    
                    performance_stats['api_calls'] += 1
                    return title, duration_min, duration_sec, thumbnail, vidid
            
            return None, None, None, None, None
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {str(e)}")
            return None, None, None, None, None

    async def title(self, link: str, videoid: Union[bool, str] = None) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"""
        title, _, _, _, _ = await self.details(link, videoid)
        return title or "Ø¹Ù†ÙˆØ§Ù† ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"

    async def duration(self, link: str, videoid: Union[bool, str] = None) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¯Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"""
        _, duration_min, _, _, _ = await self.details(link, videoid)
        return duration_min or "0:00"

    async def thumbnail(self, link: str, videoid: Union[bool, str] = None) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ØµØºØ±Ø©"""
        _, _, _, thumbnail, _ = await self.details(link, videoid)
        return thumbnail or ""

    async def video(self, link: str, videoid: Union[bool, str] = None) -> Tuple[int, str]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª"""
        try:
            if videoid:
                link = self.base + link
            if "&" in link:
                link = link.split("&")[0]
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
            cache_key = get_cache_key(link, "video_url")
            cached_data = await get_from_cache(cache_key)
            
            if cached_data and cached_data.get('success'):
                return 1, cached_data['url']
            
            cookie_file = cookies()
            cmd = [
                "yt-dlp",
                "-g",
                "-f", "best[height<=?720][width<=?1280]/best",
                "--no-playlist",
                link
            ]
            
            if cookie_file:
                cmd.extend(["--cookies", cookie_file])
            
            proc = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
            )
            
            stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=30)
            
            if stdout:
                video_url = stdout.decode().strip().split("\n")[0]
                
                # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
                cache_data = {'success': True, 'url': video_url}
                await save_to_cache(cache_key, cache_data)
                
                return 1, video_url
            
            error_msg = stderr.decode() if stderr else "Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {error_msg}")
            return 0, error_msg
            
        except asyncio.TimeoutError:
            return 0, "Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ video: {str(e)}")
            return 0, str(e)

    async def playlist(self, link: str, limit: int, videoid: Union[bool, str] = None) -> List[str]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª"""
        try:
            if videoid:
                link = self.listbase + link
            if "&" in link:
                link = link.split("&")[0]
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
            cache_key = get_cache_key(f"{link}:{limit}", "playlist")
            cached_data = await get_from_cache(cache_key)
            
            if cached_data:
                return cached_data.get('videos', [])
            
            cookie_file = cookies()
            cmd = (
                f"yt-dlp -i --compat-options no-youtube-unavailable-videos "
                f"--get-id --flat-playlist --playlist-end {limit} --skip-download "
                f'--no-warnings "{link}"'
            )
            
            if cookie_file:
                cmd += f" --cookies {cookie_file}"
            
            playlist_output = await shell_cmd(cmd)
            video_ids = [vid_id.strip() for vid_id in playlist_output.split("\n") if vid_id.strip()]
            
            # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
            cache_data = {'videos': video_ids}
            await save_to_cache(cache_key, cache_data)
            
            return video_ids
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ playlist: {str(e)}")
            return []

    async def track(self, link: str, videoid: Union[bool, str] = None) -> Tuple[Dict, str]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø³Ø§Ø± Ù…Ø¹ Ø¨Ø­Ø« Ù…Ø­Ø³Ù†"""
        try:
            if videoid:
                link = self.base + link
            if "&" in link:
                link = link.split("&")[0]
            
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø±Ø§Ø¨Ø·Ø§Ù‹ Ù…Ø¨Ø§Ø´Ø±Ø§Ù‹
            if link.startswith(("http://", "https://")):
                return await self._track_from_url(link)
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ù†Øµ
            return await self._track_from_search(link)
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ track: {str(e)}")
            return {}, None

    async def _track_from_url(self, url: str) -> Tuple[Dict, str]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø± Ù…Ù† Ø±Ø§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø±"""
        try:
            title, duration_min, duration_sec, thumbnail, vidid = await self.details(url)
            
            if title:
                track_details = {
                    "title": title,
                    "link": url,
                    "vidid": vidid,
                    "duration_min": duration_min,
                    "duration_sec": duration_sec,
                    "thumb": thumbnail,
                }
                return track_details, vidid
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ _track_from_url: {str(e)}")
        
        return await self._track_from_search(url)

    async def _track_from_search(self, query: str) -> Tuple[Dict, str]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø³Ø§Ø±"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
            cache_key = get_cache_key(query, "track_search")
            cached_data = await get_from_cache(cache_key)
            
            if cached_data:
                return cached_data['track_details'], cached_data['video_id']
            
            async with SEARCH_SEMAPHORE:
                results = VideosSearch(query, limit=1)
                search_result = await results.next()
                
                for result in search_result.get("result", []):
                    track_details = {
                        "title": result.get("title", "Unknown"),
                        "link": result.get("link", ""),
                        "vidid": result.get("id", ""),
                        "duration_min": result.get("duration", "0:00"),
                        "duration_sec": convert_duration(result.get("duration", "0:00")),
                        "thumb": result.get("thumbnails", [{}])[0].get("url", "").split("?")[0],
                        "uploader": result.get("channel", {}).get("name", ""),
                        "view_count": result.get("viewCount", {}).get("text", "0"),
                    }
                    
                    # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
                    cache_data = {
                        'track_details': track_details,
                        'video_id': result.get("id", "")
                    }
                    await save_to_cache(cache_key, cache_data)
                    
                    return track_details, result.get("id", "")
                    
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«: {str(e)}")
        
        return {}, None

    @asyncify
    def formats(self, link: str, videoid: Union[bool, str] = None) -> Tuple[List[Dict], str]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù…Ø¹ ØªÙØ§ØµÙŠÙ„ Ù…Ø­Ø³Ù†Ø©"""
        try:
            if videoid:
                link = self.base + link
            if "&" in link:
                link = link.split("&")[0]

            ytdl_opts = self.base_ytdl_opts.copy()
            cookie_file = cookies()
            if cookie_file:
                ytdl_opts["cookiefile"] = cookie_file

            with YoutubeDL(ytdl_opts) as ydl:
                info = ydl.extract_info(link, download=False)
                formats_available = []
                
                for fmt in info.get("formats", []):
                    try:
                        # ØªØ®Ø·ÙŠ ØªÙ†Ø³ÙŠÙ‚Ø§Øª DASH
                        if "dash" in str(fmt.get("format", "")).lower():
                            continue
                        
                        # ØªÙ†Ø¸ÙŠÙ ÙˆØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                        format_data = {
                            "format": fmt.get("format", "Unknown"),
                            "format_id": fmt.get("format_id", ""),
                            "ext": fmt.get("ext", ""),
                            "filesize": fmt.get("filesize") or 0,
                            "quality": fmt.get("quality") or fmt.get("height", "Unknown"),
                            "format_note": fmt.get("format_note", ""),
                            "acodec": fmt.get("acodec", ""),
                            "vcodec": fmt.get("vcodec", ""),
                            "fps": fmt.get("fps"),
                            "tbr": fmt.get("tbr"),  # Total bitrate
                            "yturl": link,
                        }
                        formats_available.append(format_data)
                        
                    except Exception as fmt_error:
                        logger.debug(f"ØªØ®Ø·ÙŠ ØªÙ†Ø³ÙŠÙ‚ Ø¨Ø³Ø¨Ø¨ Ø®Ø·Ø£: {fmt_error}")
                        continue
                
                # ØªØ±ØªÙŠØ¨ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø¬ÙˆØ¯Ø©
                formats_available.sort(
                    key=lambda x: (x.get("quality", 0) or 0, x.get("tbr", 0) or 0), 
                    reverse=True
                )
                
                return formats_available, link
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ formats: {str(e)}")
            return [], link

    async def slider(self, link: str, query_type: int, videoid: Union[bool, str] = None) -> Tuple[str, str, str, str]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ…Ø±ÙŠØ± Ù…Ø¹ Ù†ØªØ§Ø¦Ø¬ Ù…Ø­Ø³Ù†Ø©"""
        try:
            if videoid:
                link = self.base + link
            if "&" in link:
                link = link.split("&")[0]
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
            cache_key = get_cache_key(f"{link}:{query_type}", "slider")
            cached_data = await get_from_cache(cache_key)
            
            if cached_data:
                return (
                    cached_data['title'],
                    cached_data['duration'],
                    cached_data['thumbnail'],
                    cached_data['video_id']
                )
            
            async with SEARCH_SEMAPHORE:
                search = VideosSearch(link, limit=max(15, query_type + 5))
                results = await search.next()
                
                result_list = results.get("result", [])
                if result_list and len(result_list) > query_type:
                    item = result_list[query_type]
                    
                    title = item.get("title", "")
                    duration = item.get("duration", "")
                    thumbnail = item.get("thumbnails", [{}])[0].get("url", "").split("?")[0]
                    video_id = item.get("id", "")
                    
                    # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
                    cache_data = {
                        'title': title,
                        'duration': duration,
                        'thumbnail': thumbnail,
                        'video_id': video_id
                    }
                    await save_to_cache(cache_key, cache_data)
                    
                    return title, duration, thumbnail, video_id
                    
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ slider: {str(e)}")
        
        return "", "", "", ""

    async def download(self, link: str, mystic=None, video: bool = False, videoid: Union[bool, str] = None,
                      songaudio: bool = False, songvideo: bool = False, format_id: str = None, 
                      title: str = None) -> DownloadResult:
        """ØªØ­Ù…ÙŠÙ„ Ù…Ø­Ø³Ù† Ù…Ø¹ Ø¥Ø¯Ø§Ø±Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„Ù…ÙˆØ§Ø±Ø¯"""
        
        download_start_time = time.time()
        performance_stats['total_downloads'] += 1
        
        async with DOWNLOAD_SEMAPHORE:
            try:
                result = await self._download_internal(
                    link, mystic, video, videoid, songaudio, songvideo, format_id, title
                )
                
                download_time = time.time() - download_start_time
                
                if result.success:
                    performance_stats['successful_downloads'] += 1
                    logger.info(f"âœ… ØªÙ… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ {download_time:.2f}Ø«: {result.file_path}")
                else:
                    performance_stats['failed_downloads'] += 1
                    logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {result.error_message}")
                
                result.download_time = download_time
                return result
                
            except Exception as e:
                performance_stats['failed_downloads'] += 1
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {str(e)}")
                return DownloadResult(
                    success=False,
                    file_path=None,
                    error_message=str(e),
                    download_time=time.time() - download_start_time
                )

    async def _download_internal(self, link: str, mystic, video: bool, videoid: Union[bool, str],
                                songaudio: bool, songvideo: bool, format_id: str, title: str) -> DownloadResult:
        """Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø©"""
        
        if videoid:
            link = self.base + link
        if "&" in link:
            link = link.split("&")[0]
        
        loop = asyncio.get_running_loop()
        cookie_file = cookies()
        
        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
        if songvideo:
            return await self._download_song_video(link, format_id, title, cookie_file, loop)
        elif songaudio:
            return await self._download_song_audio(link, format_id, title, cookie_file, loop)
        elif video:
            return await self._download_video(link, videoid, cookie_file, loop)
        else:
            return await self._download_audio(link, cookie_file, loop)

    async def _download_audio(self, link: str, cookie_file: str, loop) -> DownloadResult:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª ÙÙ‚Ø·"""
        def audio_dl():
            try:
                ydl_opts = {
                    "format": "bestaudio[ext=m4a]/bestaudio/best",
                    "outtmpl": str(DOWNLOADS_DIR / "%(id)s.%(ext)s"),
                    "geo_bypass": True,
                    "nocheckcertificate": True,
                    "quiet": True,
                    "no_warnings": True,
                    "extract_flat": False,
                    "writethumbnail": False,
                    "writeinfojson": False,
                }
                
                if cookie_file:
                    ydl_opts["cookiefile"] = cookie_file
                
                with YoutubeDL(ydl_opts) as ydl:
                    info = ydl.extract_info(link, download=False)
                    expected_filename = str(DOWNLOADS_DIR / f"{info['id']}.{info.get('ext', 'unknown')}")
                    
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù Ù…Ø³Ø¨Ù‚Ø§Ù‹
                    if os.path.exists(expected_filename):
                        file_size = os.path.getsize(expected_filename)
                        return DownloadResult(True, expected_filename, None, file_size)
                    
                    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
                    ydl.download([link])
                    
                    # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù…Ù„
                    downloaded_files = list(DOWNLOADS_DIR.glob(f"{info['id']}.*"))
                    if downloaded_files:
                        file_path = str(downloaded_files[0])
                        file_size = os.path.getsize(file_path)
                        return DownloadResult(True, file_path, None, file_size)
                    
                    return DownloadResult(False, None, "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù…Ù„")
                    
            except Exception as e:
                return DownloadResult(False, None, f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª: {str(e)}")
        
        return await loop.run_in_executor(None, audio_dl)

    async def _download_video(self, link: str, videoid: Union[bool, str], cookie_file: str, loop) -> DownloadResult:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"""
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù…ÙŠÙ„
        if await is_on_off(config.YTDOWNLOADER):
            return await self._download_video_file(link, cookie_file, loop)
        else:
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø± ÙÙ‚Ø·
            result_code, video_url = await self.video(link, videoid)
            if result_code == 1:
                return DownloadResult(True, video_url, None)
            else:
                return DownloadResult(False, None, video_url)

    async def _download_video_file(self, link: str, cookie_file: str, loop) -> DownloadResult:
        """ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„ÙØ¹Ù„ÙŠ"""
        def video_dl():
            try:
                ydl_opts = {
                    "format": "(bestvideo[height<=?720][width<=?1280][ext=mp4])+(bestaudio[ext=m4a])/best[height<=?720]",
                    "outtmpl": str(DOWNLOADS_DIR / "%(id)s.%(ext)s"),
                    "geo_bypass": True,
                    "nocheckcertificate": True,
                    "quiet": True,
                    "no_warnings": True,
                    "merge_output_format": "mp4",
                }
                
                if cookie_file:
                    ydl_opts["cookiefile"] = cookie_file
                
                with YoutubeDL(ydl_opts) as ydl:
                    info = ydl.extract_info(link, download=False)
                    expected_filename = str(DOWNLOADS_DIR / f"{info['id']}.mp4")
                    
                    if os.path.exists(expected_filename):
                        file_size = os.path.getsize(expected_filename)
                        return DownloadResult(True, expected_filename, None, file_size)
                    
                    ydl.download([link])
                    
                    if os.path.exists(expected_filename):
                        file_size = os.path.getsize(expected_filename)
                        return DownloadResult(True, expected_filename, None, file_size)
                    
                    return DownloadResult(False, None, "ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ")
                    
            except Exception as e:
                return DownloadResult(False, None, f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {str(e)}")
        
        return await loop.run_in_executor(None, video_dl)

    async def _download_song_video(self, link: str, format_id: str, title: str, cookie_file: str, loop) -> DownloadResult:
        """ØªØ­Ù…ÙŠÙ„ ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø£ØºÙ†ÙŠØ© Ø¨Ø¬ÙˆØ¯Ø© Ù…Ø­Ø¯Ø¯Ø©"""
        def song_video_dl():
            try:
                safe_title = re.sub(r'[^\w\s-]', '', title)[:50]
                
                ydl_opts = {
                    "format": f"{format_id}+bestaudio/best",
                    "outtmpl": str(DOWNLOADS_DIR / f"{safe_title}.%(ext)s"),
                    "geo_bypass": True,
                    "nocheckcertificate": True,
                    "quiet": True,
                    "no_warnings": True,
                    "merge_output_format": "mp4",
                }
                
                if cookie_file:
                    ydl_opts["cookiefile"] = cookie_file
                
                with YoutubeDL(ydl_opts) as ydl:
                    ydl.download([link])
                
                expected_path = DOWNLOADS_DIR / f"{safe_title}.mp4"
                if expected_path.exists():
                    file_size = expected_path.stat().st_size
                    return DownloadResult(True, str(expected_path), None, file_size)
                
                return DownloadResult(False, None, "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„ÙÙŠØ¯ÙŠÙˆ")
                
            except Exception as e:
                return DownloadResult(False, None, f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø£ØºÙ†ÙŠØ©: {str(e)}")
        
        return await loop.run_in_executor(None, song_video_dl)

    async def _download_song_audio(self, link: str, format_id: str, title: str, cookie_file: str, loop) -> DownloadResult:
        """ØªØ­Ù…ÙŠÙ„ ØµÙˆØª Ø§Ù„Ø£ØºÙ†ÙŠØ© Ø¨Ø¬ÙˆØ¯Ø© Ù…Ø­Ø¯Ø¯Ø©"""
        def song_audio_dl():
            try:
                safe_title = re.sub(r'[^\w\s-]', '', title)[:50]
                
                ydl_opts = {
                    "format": format_id,
                    "outtmpl": str(DOWNLOADS_DIR / f"{safe_title}.%(ext)s"),
                    "geo_bypass": True,
                    "nocheckcertificate": True,
                    "quiet": True,
                    "no_warnings": True,
                    "postprocessors": [{
                        "key": "FFmpegExtractAudio",
                        "preferredcodec": "mp3",
                        "preferredquality": "192",
                    }],
                }
                
                if cookie_file:
                    ydl_opts["cookiefile"] = cookie_file
                
                with YoutubeDL(ydl_opts) as ydl:
                    ydl.download([link])
                
                expected_path = DOWNLOADS_DIR / f"{safe_title}.mp3"
                if expected_path.exists():
                    file_size = expected_path.stat().st_size
                    return DownloadResult(True, str(expected_path), None, file_size)
                
                return DownloadResult(False, None, "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„ØµÙˆØª")
                
            except Exception as e:
                return DownloadResult(False, None, f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ ØµÙˆØª Ø§Ù„Ø£ØºÙ†ÙŠØ©: {str(e)}")
        
        return await loop.run_in_executor(None, song_audio_dl)

    async def get_performance_stats(self) -> Dict:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        return get_performance_report()

    async def cleanup_cache(self, max_age_hours: int = 24):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙƒØ§Ø´ Ø§Ù„Ù‚Ø¯ÙŠÙ…"""
        try:
            current_time = time.time()
            deleted_count = 0
            
            for cache_file in CACHE_DIR.glob("*.json"):
                file_age = current_time - cache_file.stat().st_mtime
                if file_age > (max_age_hours * 3600):
                    cache_file.unlink()
                    deleted_count += 1
            
            logger.info(f"ğŸ§¹ ØªÙ… Ø­Ø°Ù {deleted_count} Ù…Ù„Ù ÙƒØ§Ø´ Ù‚Ø¯ÙŠÙ…")
            return deleted_count
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙƒØ§Ø´: {str(e)}")
            return 0

    async def cleanup_downloads(self, max_age_hours: int = 2):
        """ØªÙ†Ø¸ÙŠÙ Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        try:
            current_time = time.time()
            deleted_count = 0
            freed_space = 0
            
            for download_file in DOWNLOADS_DIR.iterdir():
                if download_file.is_file():
                    file_age = current_time - download_file.stat().st_mtime
                    if file_age > (max_age_hours * 3600):
                        file_size = download_file.stat().st_size
                        download_file.unlink()
                        deleted_count += 1
                        freed_space += file_size
            
            freed_mb = freed_space / (1024 * 1024)
            logger.info(f"ğŸ§¹ ØªÙ… Ø­Ø°Ù {deleted_count} Ù…Ù„Ù ØªØ­Ù…ÙŠÙ„ØŒ ØªÙˆÙÙŠØ± {freed_mb:.1f} MB")
            return deleted_count, freed_mb
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªØ­Ù…ÙŠÙ„Ø§Øª: {str(e)}")
            return 0, 0

# =============================================================================
# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø«ÙŠÙ„ Ø§Ù„Ø¹Ø§Ù…
# =============================================================================

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ ÙˆØ­ÙŠØ¯ Ù…Ù† API
youtube = YouTubeAPI()

# Ø¯ÙˆØ§Ù„ Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ… (deprecated - Ø§Ø³ØªØ®Ø¯Ù… youtube Ù…Ø¨Ø§Ø´Ø±Ø©)
YoutubeAPI = YouTubeAPI  # Ù„Ù„ØªÙˆØ§ÙÙ‚

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ù‡Ù…Ø© ØªÙ†Ø¸ÙŠÙ Ø¯ÙˆØ±ÙŠØ©
async def periodic_cleanup():
    """Ù…Ù‡Ù…Ø© ØªÙ†Ø¸ÙŠÙ Ø¯ÙˆØ±ÙŠØ©"""
    while True:
        try:
            await asyncio.sleep(3600)  # ÙƒÙ„ Ø³Ø§Ø¹Ø©
            await youtube.cleanup_cache(24)  # Ø­Ø°Ù Ø§Ù„ÙƒØ§Ø´ Ø£Ù‚Ø¯Ù… Ù…Ù† 24 Ø³Ø§Ø¹Ø©
            await youtube.cleanup_downloads(2)  # Ø­Ø°Ù Ø§Ù„ØªØ­Ù…ÙŠÙ„Ø§Øª Ø£Ù‚Ø¯Ù… Ù…Ù† Ø³Ø§Ø¹ØªÙŠÙ†
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¯ÙˆØ±ÙŠ: {str(e)}")

# Ø¨Ø¯Ø¡ Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ
try:
    asyncio.create_task(periodic_cleanup())
    logger.info("ğŸš€ ØªÙ… ØªØ´ØºÙŠÙ„ Ù†Ø¸Ø§Ù… YouTube Ø§Ù„Ù…Ø­Ø³Ù† Ù…Ø¹ Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ")
except Exception as e:
    logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¨Ø¯Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù…: {str(e)}")

# Ø±Ø³Ø§Ù„Ø© ØªØ±Ø­ÙŠØ¨
logger.info("ğŸµ YouTube Platform Handler - Enhanced Edition ØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡ Ø¨Ù†Ø¬Ø§Ø­!")
